---
title: "RAG vs 파인튜닝 — 왜 우리는 RAG를 선택했나"
date: 2026-02-06T02:20:00+09:00
categories: [AI, Decision]
tags: [RAG, Fine-tuning, LLM, 아키텍처결정]
toc: true
toc_sticky: true
excerpt: "AssoAI는 왜 파인튜닝 대신 RAG를 선택했을까요? 임기제 조직, 빈번한 데이터 변경, 조직별 격리 — 학생회 SaaS의 현실이 결정을 내렸습니다 🐧"
---

AI 제품을 만들 때 가장 먼저 맞닥뜨리는 분기점: **RAG vs Fine-tuning**. AssoAI는 RAG를 선택했습니다. 그 이유를 정리합니다 🐧

## RAG vs Fine-tuning 비교

|  | RAG | Fine-tuning |
|---|---|---|
| **데이터 반영 속도** | 즉시 (업로드 즉시 검색 가능) | 수 시간~수 일 (재학습 필요) |
| **비용** | 임베딩 1회 + 추론 비용 | GPU 학습 비용 + 추론 비용 |
| **할루시네이션** | 출처 기반 답변으로 제어 가능 | 학습 데이터에 의존, 제어 어려움 |
| **멀티테넌트** | 검색 시 org_id로 격리 | 조직별 모델 분리 필요 |
| **최신성** | 항상 최신 데이터 반영 | 학습 시점 데이터에 고정 |
| **구현 복잡도** | 중간 (검색 파이프라인) | 높음 (학습 파이프라인 + MLOps) |

## 학생회에서 RAG가 압도적인 이유

### 1. 임기제 조직의 현실

학생회는 보통 **1년 임기**입니다. 매년 집행부가 바뀌면:
- 담당자가 전원 교체됨
- 제휴 업체가 갱신/변경됨
- 예산 구조가 리셋됨
- 지난 기수의 데이터를 "참고"만 할 뿐 사용 방식이 달라짐

파인튜닝은 이 변화를 따라갈 수 없습니다. 매 임기마다 재학습? 비용과 시간 모두 비현실적입니다.

RAG는 데이터가 바뀌면 **바로 반영**됩니다. 새 임기가 시작되면 새로운 데이터를 입력하기만 하면 됩니다.

### 2. 조직별 완전 격리

AssoAI는 SaaS입니다. 수십~수백 개의 학생회/동아리가 같은 시스템을 씁니다.

```typescript
// 모든 검색에 org_id 필터 필수
const results = await searchSimilarChunks(query, orgId, 5)
// SQL에도 강제
if (!sql.includes('org_id')) return null // 거부!
```

RAG에서는 검색 시점에 `org_id`로 격리하면 끝입니다. 파인튜닝이라면 조직마다 별도 모델을 유지해야 합니다. 100개 조직 = 100개 모델 = 유지보수 지옥.

### 3. 데이터 변경 빈도

학생회 데이터는 **매일** 바뀝니다:
- 오늘 회의록이 추가됨
- 지출이 기록됨
- 행사 상태가 업데이트됨
- 새 제휴가 체결됨

파인튜닝은 이런 변화를 실시간으로 반영할 수 없습니다. RAG는 **DB를 직접 조회**하므로 항상 최신 상태입니다.

## 비용 분석

### RAG 비용 구조

```
임베딩 생성: ~$0.0001/1K tokens (1회성)
추론 비용:   ~$0.001-0.01/query (Gemini Flash)
인프라:      Supabase pgvector (무료 티어 가능)
──────────────────────────────
월 1만 쿼리 기준: ~$10-50/월
```

### Fine-tuning 비용 구조

```
학습 비용:   $50-500/회 (데이터 크기 의존)
재학습:      데이터 변경 시마다 (월 1-4회)
모델 호스팅: $50-200/월 (GPU 인스턴스)
──────────────────────────────
월 비용: $200-1,000+/월 (단일 조직)
```

SaaS에서 조직당 월 비용이 수백 달러? 학생회 SaaS의 가격대에서는 불가능합니다.

## RAG의 단점과 대응

RAG가 만능은 아닙니다:

**단점 1: 검색 실패 시 답변 불가**
→ 대응: `assessSearchQuality`로 신뢰도를 평가하고, 부족하면 솔직히 "모릅니다"라고 답변

**단점 2: 복잡한 추론에 한계**
→ 대응: VIEW 패턴 매칭으로 흔한 쿼리를 빠르게 처리, 복잡한 건 NL→SQL로 처리

**단점 3: 컨텍스트 윈도우 제한**
→ 대응: 리랭킹으로 상위 N개만 선별, 계층적 컨텍스트로 토큰 최적화

## 하이브리드의 가능성

미래에는 **RAG + Fine-tuning 하이브리드**도 고려할 수 있습니다:

- **Base Model Fine-tuning**: 학생회 도메인 용어와 응답 스타일을 학습한 경량 모델
- **RAG for Facts**: 실시간 데이터는 RAG로 검색

하지만 현재 AssoAI의 규모에서는 RAG 단독이 최적의 선택입니다. 구현 복잡도, 비용, 유지보수 — 모든 면에서 그렇습니다.

## 결론

AssoAI가 RAG를 선택한 이유를 한 줄로 요약하면:

> **"매년 바뀌는 조직, 매일 바뀌는 데이터, 수백 개의 테넌트 — 파인튜닝이 감당할 수 있는 영역이 아닙니다."**

RAG는 **검색 기반 사실 제공**에 충실하고, 파인튜닝은 **스타일과 추론 능력 개선**에 적합합니다. 학생회 SaaS에서 필요한 건 전자입니다 🐧

---

*AssoAI는 학생회·동아리를 위한 AI 운영 도구입니다. [asso-ai.kr](https://asso-ai.kr)*
